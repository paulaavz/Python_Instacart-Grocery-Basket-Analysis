{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a424005f",
   "metadata": {},
   "source": [
    "# 4.9.1 IC_Intro to Data Visualization with Python_Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12952c4e",
   "metadata": {},
   "source": [
    "#### Context:\n",
    "- In this task, you’ll revisit some of the fundamental data preparation and combination techniques you learned in earlier Exercises as you incorporate an additional dataframe into your project. Then, you’ll move on to generating visualizations for your analysis.\n",
    "- The senior Instacart officers have given you a new data set of customer information to go along with your product and order data. \n",
    "    - In part 1 of the task, you’ll need to incorporate this new data set into your project. \n",
    "    - In part 2, you’ll create some visualizations, conduct some exploratory analysis, and begin wrapping up everything you’ve done in this Achievement in preparation for the final task in the next Exercise, where you’ll write up a report for your client.\n",
    "\n",
    "#### Directions Part 1\n",
    "- 1. Download the customer data set and add it to your “Original Data” folder.\n",
    "- 2. Create a new notebook in your “Scripts” folder for part 1 of this task.\n",
    "- 3. Import your analysis libraries, as well as your new customer data set as a dataframe.\n",
    "- 4. Wrangle the data so that it follows consistent logic; for example, rename columns with illogical names and drop columns that don’t add anything to your analysis.\n",
    "- 5. Complete the fundamental data quality and consistency checks you’ve learned throughout this Achievement; for example, check for and address missing values and duplicates, and convert any mixed-type data.\n",
    "- 6. Combine your customer data with the rest of your prepared Instacart data. (Hint: Make sure the key columns are the same data type!)\n",
    "- 7. Ensure your notebook contains logical titles, section headings, and descriptive code comments.\n",
    "- 8. Export this new dataframe as a pickle file so you can continue to use it in the second part of this task.\n",
    "- 9. Save your notebook so that you can send it to your tutor for review after completing part 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aeb4ec",
   "metadata": {},
   "source": [
    "## This script contains the following points:\n",
    "\n",
    "#### 0. Importing Libraries\n",
    "#### 1. Loading and Checking the Data\n",
    "#### 2. Wrangling the Data\n",
    "#### 3. Data Quality and Consistency Checks \n",
    "#### 4. Combining Customer Data with Previously Prepared Data\n",
    "#### 5. Exporting the New Dataframe as a Pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3e9f0",
   "metadata": {},
   "source": [
    "## 0. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91ccdfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries: pandas, NumPy, os, \n",
    "# Import Visualization Libraries: matplotlib, seaborn, and scipy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e284ec",
   "metadata": {},
   "source": [
    "## 1. Loading and Checking the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "184de5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the data files, folder path to my main project folder is now stored within variable 'path'\n",
    "\n",
    "path = r'/Users/pau/06-05-2024 Instacart Basket Analysis'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a746cdc2",
   "metadata": {},
   "source": [
    "#### Loading the \"customers.csv\" data set into my Jupyter notebook using the os library as df_customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac277fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load \"customers.csv\" from the \"Original Data\" folder as \"df_customers\"\n",
    "\n",
    "df_customers = pd.read_csv(os.path.join(path, '02 Data', 'Original Data', 'customers.csv'), index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0286894a",
   "metadata": {},
   "source": [
    "#### Checking the dimensions of the imported dataframe and if the data is correctly loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "099adafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id First Name    Surnam  Gender       STATE  Age date_joined  \\\n",
      "0    26711    Deborah  Esquivel  Female    Missouri   48    1/1/2017   \n",
      "1    33890   Patricia      Hart  Female  New Mexico   36    1/1/2017   \n",
      "2    65803    Kenneth    Farley    Male       Idaho   35    1/1/2017   \n",
      "3   125935   Michelle     Hicks  Female        Iowa   40    1/1/2017   \n",
      "4   130797        Ann   Gilmore  Female    Maryland   26    1/1/2017   \n",
      "\n",
      "   n_dependants fam_status  income  \n",
      "0             3    married  165665  \n",
      "1             0     single   59285  \n",
      "2             2    married   99568  \n",
      "3             0     single   42049  \n",
      "4             1    married   40374  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 206209 entries, 0 to 206208\n",
      "Data columns (total 10 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   user_id       206209 non-null  int64 \n",
      " 1   First Name    194950 non-null  object\n",
      " 2   Surnam        206209 non-null  object\n",
      " 3   Gender        206209 non-null  object\n",
      " 4   STATE         206209 non-null  object\n",
      " 5   Age           206209 non-null  int64 \n",
      " 6   date_joined   206209 non-null  object\n",
      " 7   n_dependants  206209 non-null  int64 \n",
      " 8   fam_status    206209 non-null  object\n",
      " 9   income        206209 non-null  int64 \n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 15.7+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(206209, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking \"customers.csv\" data is correctly loaded\n",
    "\n",
    "print(df_customers.head()) # to ensure nothing looks off about our imported dataframes.\n",
    "print(df_customers.info())\n",
    "df_customers.shape # to confirm the total size of our imported df. Great way to get a feel for the data and have a better idea how to proceed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e40b0a9",
   "metadata": {},
   "source": [
    "## 2. Wrangling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b619da",
   "metadata": {},
   "source": [
    "#### Wrangle the data so that it follows consistent logic:\n",
    "\n",
    "- **rename columns** with illogical names\n",
    "- **drop columns** that don’t add anything to our analysis\n",
    "- change wrong **data types** \n",
    "- **transpose** data if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d290a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns for consistency and clarity\n",
    "\n",
    "df_customers.rename(columns={'First Name': 'first_name', 'Surnam': 'surname', 'Gender': 'gender', 'STATE': 'state', 'Age': 'age', 'n_dependants': 'dependants', 'fam_status': 'family_status', 'income': 'income'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f160a920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'first_name', 'surname', 'gender', 'state', 'age',\n",
      "       'date_joined', 'dependants', 'family_status', 'income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Verify the names of the columns after making changes\n",
    "\n",
    "print(df_customers.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3af91606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id           int64\n",
      "first_name       object\n",
      "surname          object\n",
      "gender           object\n",
      "state            object\n",
      "age               int64\n",
      "date_joined      object\n",
      "dependants        int64\n",
      "family_status    object\n",
      "income            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types and make adjustments as needed\n",
    "\n",
    "print(df_customers.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb880661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"user_id\" data type to \"string\"\n",
    "\n",
    "df_customers['user_id'] = df_customers['user_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb7ae303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert \"date_joined\" to data type datetime\n",
    "\n",
    "df_customers['date_joined'] = pd.to_datetime(df_customers['date_joined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7386c557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id                  object\n",
      "first_name               object\n",
      "surname                  object\n",
      "gender                   object\n",
      "state                    object\n",
      "age                       int64\n",
      "date_joined      datetime64[ns]\n",
      "dependants                int64\n",
      "family_status            object\n",
      "income                    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types after making changes\n",
    "\n",
    "print(df_customers.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65659c0f",
   "metadata": {},
   "source": [
    "## 3. Data Quality and Consistency Checks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252fed84",
   "metadata": {},
   "source": [
    "#### Complete the fundamental data quality and consistency checks:\n",
    "- Find and address **mixed type** variables in the dataframe\n",
    "- Find and address **missing values** in the dataframe\n",
    "- Find and address **duplicate values** in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcce0b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_name\n"
     ]
    }
   ],
   "source": [
    "# Check for mixed data types in each column\n",
    "\n",
    "for col in df_customers.columns.tolist():\n",
    "    weird = (df_customers[[col]].map(type) != df_customers[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "    if len (df_customers[weird]) > 0:\n",
    "        print (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "837d21c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"first_name\" column should have a data type \"string\"\n",
    "\n",
    "df_customers['first_name'] = df_customers['first_name'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a874e4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id                  object\n",
      "first_name               object\n",
      "surname                  object\n",
      "gender                   object\n",
      "state                    object\n",
      "age                       int64\n",
      "date_joined      datetime64[ns]\n",
      "dependants                int64\n",
      "family_status            object\n",
      "income                    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types after making changes\n",
    "\n",
    "print(df_customers.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f085acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for mixed data types\n",
    "\n",
    "for col in df_customers.columns.tolist():\n",
    "    weird = (df_customers[[col]].map(type) != df_customers[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "    if len (df_customers[weird]) > 0:\n",
    "        print (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a6e6e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id          0\n",
      "first_name       0\n",
      "surname          0\n",
      "gender           0\n",
      "state            0\n",
      "age              0\n",
      "date_joined      0\n",
      "dependants       0\n",
      "family_status    0\n",
      "income           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "\n",
    "print(df_customers.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bf04e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "\n",
    "print(\"Duplicates:\", df_customers.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "732c20af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>date_joined</th>\n",
       "      <th>dependants</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>206209.000000</td>\n",
       "      <td>206209</td>\n",
       "      <td>206209.000000</td>\n",
       "      <td>206209.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49.501646</td>\n",
       "      <td>2018-08-17 03:06:30.029532928</td>\n",
       "      <td>1.499823</td>\n",
       "      <td>94632.852548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25903.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>33.000000</td>\n",
       "      <td>2017-10-23 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59874.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>2018-08-16 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>93547.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>66.000000</td>\n",
       "      <td>2019-06-10 00:00:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>124244.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>81.000000</td>\n",
       "      <td>2020-04-01 00:00:00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>593901.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>18.480962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.118433</td>\n",
       "      <td>42473.786988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age                    date_joined     dependants  \\\n",
       "count  206209.000000                         206209  206209.000000   \n",
       "mean       49.501646  2018-08-17 03:06:30.029532928       1.499823   \n",
       "min        18.000000            2017-01-01 00:00:00       0.000000   \n",
       "25%        33.000000            2017-10-23 00:00:00       0.000000   \n",
       "50%        49.000000            2018-08-16 00:00:00       1.000000   \n",
       "75%        66.000000            2019-06-10 00:00:00       3.000000   \n",
       "max        81.000000            2020-04-01 00:00:00       3.000000   \n",
       "std        18.480962                            NaN       1.118433   \n",
       "\n",
       "              income  \n",
       "count  206209.000000  \n",
       "mean    94632.852548  \n",
       "min     25903.000000  \n",
       "25%     59874.000000  \n",
       "50%     93547.000000  \n",
       "75%    124244.000000  \n",
       "max    593901.000000  \n",
       "std     42473.786988  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the descriptive stats for anything unusal\n",
    "\n",
    "df_customers.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647e181a",
   "metadata": {},
   "source": [
    "## 4. Combining Customer Data with Previously Prepared Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846f9b26",
   "metadata": {},
   "source": [
    "Loading the prepared Instacart data from task 4.8 \"ords_prods_merge_new_var_group_agg.pkl\" as \"df_ords_prods_new\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a8e00aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the most up-to-date version of the previously prepared data as \"df_ords_prods_new\"\n",
    "\n",
    "df_ords_prods_new = pd.read_pickle(os.path.join(path, '02 Data', 'Prepared Data', 'ords_prods_merge_new_var_group_agg.pkl'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ddb4e5",
   "metadata": {},
   "source": [
    "Checking the dimensions of the imported dataframe and if the data is correctly loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dad0a62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id                product_name  aisle_id  department_id  prices  \\\n",
      "0           1  Chocolate Sandwich Cookies        61             19     5.8   \n",
      "1           1  Chocolate Sandwich Cookies        61             19     5.8   \n",
      "2           1  Chocolate Sandwich Cookies        61             19     5.8   \n",
      "3           1  Chocolate Sandwich Cookies        61             19     5.8   \n",
      "4           1  Chocolate Sandwich Cookies        61             19     5.8   \n",
      "\n",
      "   order_id  user_id  order_number  orders_day_of_week  order_hour_of_day  \\\n",
      "0   3139998      138            28                   6                 11   \n",
      "1   1977647      138            30                   6                 17   \n",
      "2    389851      709             2                   0                 21   \n",
      "3    652770      764             1                   3                 13   \n",
      "4   1813452      764             3                   4                 17   \n",
      "\n",
      "   ...    price_range_loc     busiest_day  busiest_days  \\\n",
      "0  ...  Mid-range product  Regularly busy  Regular days   \n",
      "1  ...  Mid-range product  Regularly busy  Regular days   \n",
      "2  ...  Mid-range product     Busiest day  Busiest days   \n",
      "3  ...  Mid-range product  Regularly busy  Slowest days   \n",
      "4  ...  Mid-range product      Least busy  Slowest days   \n",
      "\n",
      "   busiest_period_of_day max_order      loyalty_flag mean_product_price  \\\n",
      "0            Most orders        32  Regular customer           6.935811   \n",
      "1         Average orders        32  Regular customer           6.935811   \n",
      "2         Average orders         5      New customer           7.930208   \n",
      "3            Most orders         3      New customer           4.972414   \n",
      "4         Average orders         3      New customer           4.972414   \n",
      "\n",
      "  spending_flag order_frequency     frequency_flag  \n",
      "0   Low_spender             8.0  Frequent customer  \n",
      "1   Low_spender             8.0  Frequent customer  \n",
      "2   Low_spender             8.0  Frequent customer  \n",
      "3   Low_spender             9.0  Frequent customer  \n",
      "4   Low_spender             9.0  Frequent customer  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32404859 entries, 0 to 32404858\n",
      "Data columns (total 25 columns):\n",
      " #   Column                  Dtype   \n",
      "---  ------                  -----   \n",
      " 0   product_id              int64   \n",
      " 1   product_name            object  \n",
      " 2   aisle_id                int64   \n",
      " 3   department_id           int64   \n",
      " 4   prices                  float64 \n",
      " 5   order_id                int64   \n",
      " 6   user_id                 int64   \n",
      " 7   order_number            int64   \n",
      " 8   orders_day_of_week      int64   \n",
      " 9   order_hour_of_day       int64   \n",
      " 10  days_since_prior_order  float64 \n",
      " 11  is_first_order          int64   \n",
      " 12  add_to_cart_order       int64   \n",
      " 13  reordered               int64   \n",
      " 14  _merge                  category\n",
      " 15  price_range_loc         object  \n",
      " 16  busiest_day             object  \n",
      " 17  busiest_days            object  \n",
      " 18  busiest_period_of_day   object  \n",
      " 19  max_order               int64   \n",
      " 20  loyalty_flag            object  \n",
      " 21  mean_product_price      float64 \n",
      " 22  spending_flag           object  \n",
      " 23  order_frequency         float64 \n",
      " 24  frequency_flag          object  \n",
      "dtypes: category(1), float64(4), int64(12), object(8)\n",
      "memory usage: 5.8+ GB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(32404859, 25)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking \"ords_prods_merge_new_var_group_agg.pkl\" data is correctly loaded\n",
    "\n",
    "print(df_ords_prods_new.head()) \n",
    "print(df_ords_prods_new.info()) \n",
    "df_ords_prods_new.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb0e7db",
   "metadata": {},
   "source": [
    "#### Combining our customer data with the rest of our prepared Instacart data. \n",
    "\n",
    "- 1. Finding key or common identifier column that brings the two data sets together: \n",
    "    - Both dataframes have the \"user_id\" column, which we can use to combine them.\n",
    "    - It should be a fully matching \"user_id\" column.\n",
    "- 2. To combine both dataframes we have to make sure that key columns are the same data type\n",
    "    - \"user_id\" in the \"df_ords_prods_new\" dataframe must first be converted to \"string\" to match the \"user_id\" column in \"df_customers\"\n",
    "    - The other identifier columns in the dataframe can also be converted to \"string\":\n",
    "        - \"product_id\"\n",
    "        - \"aisle_id\"\n",
    "        - \"department_id\"\n",
    "        - \"order_id\"\n",
    "        - \"user_id\"¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc9e0cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the identifier columns in \"df_ords_prods_new\" to \"string\"\n",
    "\n",
    "df_ords_prods_new[['product_id', 'aisle_id', 'department_id', 'order_id', 'user_id']] = df_ords_prods_new[['product_id', 'aisle_id', 'department_id', 'order_id', 'user_id']].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aace5544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id                  object\n",
      "product_name                object\n",
      "aisle_id                    object\n",
      "department_id               object\n",
      "prices                     float64\n",
      "order_id                    object\n",
      "user_id                     object\n",
      "order_number                 int64\n",
      "orders_day_of_week           int64\n",
      "order_hour_of_day            int64\n",
      "days_since_prior_order     float64\n",
      "is_first_order               int64\n",
      "add_to_cart_order            int64\n",
      "reordered                    int64\n",
      "_merge                    category\n",
      "price_range_loc             object\n",
      "busiest_day                 object\n",
      "busiest_days                object\n",
      "busiest_period_of_day       object\n",
      "max_order                    int64\n",
      "loyalty_flag                object\n",
      "mean_product_price         float64\n",
      "spending_flag               object\n",
      "order_frequency            float64\n",
      "frequency_flag              object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check the results of the change\n",
    "\n",
    "print(df_ords_prods_new.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fec793c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the existing \"_merge\" column from \"df_ords_prods_new\"\n",
    "\n",
    "df_ords_prods_new = df_ords_prods_new.drop(columns=['_merge'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a106149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['product_id', 'product_name', 'aisle_id', 'department_id', 'prices',\n",
      "       'order_id', 'user_id', 'order_number', 'orders_day_of_week',\n",
      "       'order_hour_of_day', 'days_since_prior_order', 'is_first_order',\n",
      "       'add_to_cart_order', 'reordered', 'price_range_loc', 'busiest_day',\n",
      "       'busiest_days', 'busiest_period_of_day', 'max_order', 'loyalty_flag',\n",
      "       'mean_product_price', 'spending_flag', 'order_frequency',\n",
      "       'frequency_flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the columns after the change\n",
    "\n",
    "print(df_ords_prods_new.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adfa9df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two dataframes using the default inner join\n",
    "\n",
    "df_final_merged = df_ords_prods_new.merge(df_customers, on='user_id', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fea38738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "      <th>prices</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>orders_day_of_week</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>...</th>\n",
       "      <th>first_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>gender</th>\n",
       "      <th>state</th>\n",
       "      <th>age</th>\n",
       "      <th>date_joined</th>\n",
       "      <th>dependants</th>\n",
       "      <th>family_status</th>\n",
       "      <th>income</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Chocolate Sandwich Cookies</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>5.8</td>\n",
       "      <td>3139998</td>\n",
       "      <td>138</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>Charles</td>\n",
       "      <td>Cox</td>\n",
       "      <td>Male</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>81</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>married</td>\n",
       "      <td>49620</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Chocolate Sandwich Cookies</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1977647</td>\n",
       "      <td>138</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>Charles</td>\n",
       "      <td>Cox</td>\n",
       "      <td>Male</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>81</td>\n",
       "      <td>2019-08-01</td>\n",
       "      <td>1</td>\n",
       "      <td>married</td>\n",
       "      <td>49620</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Chocolate Sandwich Cookies</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>5.8</td>\n",
       "      <td>389851</td>\n",
       "      <td>709</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>Deborah</td>\n",
       "      <td>Glass</td>\n",
       "      <td>Female</td>\n",
       "      <td>Vermont</td>\n",
       "      <td>66</td>\n",
       "      <td>2018-06-16</td>\n",
       "      <td>2</td>\n",
       "      <td>married</td>\n",
       "      <td>158302</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Chocolate Sandwich Cookies</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>5.8</td>\n",
       "      <td>652770</td>\n",
       "      <td>764</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>Heather</td>\n",
       "      <td>Myers</td>\n",
       "      <td>Female</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>40</td>\n",
       "      <td>2020-02-09</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>31308</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Chocolate Sandwich Cookies</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1813452</td>\n",
       "      <td>764</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>Heather</td>\n",
       "      <td>Myers</td>\n",
       "      <td>Female</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>40</td>\n",
       "      <td>2020-02-09</td>\n",
       "      <td>3</td>\n",
       "      <td>married</td>\n",
       "      <td>31308</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  product_id                product_name aisle_id department_id  prices  \\\n",
       "0          1  Chocolate Sandwich Cookies       61            19     5.8   \n",
       "1          1  Chocolate Sandwich Cookies       61            19     5.8   \n",
       "2          1  Chocolate Sandwich Cookies       61            19     5.8   \n",
       "3          1  Chocolate Sandwich Cookies       61            19     5.8   \n",
       "4          1  Chocolate Sandwich Cookies       61            19     5.8   \n",
       "\n",
       "  order_id user_id  order_number  orders_day_of_week  order_hour_of_day  ...  \\\n",
       "0  3139998     138            28                   6                 11  ...   \n",
       "1  1977647     138            30                   6                 17  ...   \n",
       "2   389851     709             2                   0                 21  ...   \n",
       "3   652770     764             1                   3                 13  ...   \n",
       "4  1813452     764             3                   4                 17  ...   \n",
       "\n",
       "   first_name  surname  gender      state age date_joined dependants  \\\n",
       "0     Charles      Cox    Male  Minnesota  81  2019-08-01          1   \n",
       "1     Charles      Cox    Male  Minnesota  81  2019-08-01          1   \n",
       "2     Deborah    Glass  Female    Vermont  66  2018-06-16          2   \n",
       "3     Heather    Myers  Female  Wisconsin  40  2020-02-09          3   \n",
       "4     Heather    Myers  Female  Wisconsin  40  2020-02-09          3   \n",
       "\n",
       "  family_status  income _merge  \n",
       "0       married   49620   both  \n",
       "1       married   49620   both  \n",
       "2       married  158302   both  \n",
       "3       married   31308   both  \n",
       "4       married   31308   both  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming the results of the merge\n",
    "\n",
    "df_final_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5acbbc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32404859 entries, 0 to 32404858\n",
      "Data columns (total 34 columns):\n",
      " #   Column                  Dtype         \n",
      "---  ------                  -----         \n",
      " 0   product_id              object        \n",
      " 1   product_name            object        \n",
      " 2   aisle_id                object        \n",
      " 3   department_id           object        \n",
      " 4   prices                  float64       \n",
      " 5   order_id                object        \n",
      " 6   user_id                 object        \n",
      " 7   order_number            int64         \n",
      " 8   orders_day_of_week      int64         \n",
      " 9   order_hour_of_day       int64         \n",
      " 10  days_since_prior_order  float64       \n",
      " 11  is_first_order          int64         \n",
      " 12  add_to_cart_order       int64         \n",
      " 13  reordered               int64         \n",
      " 14  price_range_loc         object        \n",
      " 15  busiest_day             object        \n",
      " 16  busiest_days            object        \n",
      " 17  busiest_period_of_day   object        \n",
      " 18  max_order               int64         \n",
      " 19  loyalty_flag            object        \n",
      " 20  mean_product_price      float64       \n",
      " 21  spending_flag           object        \n",
      " 22  order_frequency         float64       \n",
      " 23  frequency_flag          object        \n",
      " 24  first_name              object        \n",
      " 25  surname                 object        \n",
      " 26  gender                  object        \n",
      " 27  state                   object        \n",
      " 28  age                     int64         \n",
      " 29  date_joined             datetime64[ns]\n",
      " 30  dependants              int64         \n",
      " 31  family_status           object        \n",
      " 32  income                  int64         \n",
      " 33  _merge                  category      \n",
      "dtypes: category(1), datetime64[ns](1), float64(4), int64(10), object(18)\n",
      "memory usage: 8.0+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Check the details of the new \"df_final_merged\" dataframe\n",
    "\n",
    "print(df_final_merged.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf181c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32404859, 34)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the results of the merged data\n",
    "\n",
    "df_final_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa3de822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_merge\n",
       "both          32404859\n",
       "left_only            0\n",
       "right_only           0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check \"value_counts\" after inner join\n",
    "\n",
    "df_final_merged['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86f03d6",
   "metadata": {},
   "source": [
    "#### Checking the results of the rows and cols:\n",
    "\n",
    "#### -  df_ords_prods_new\n",
    "(32404859, 25) after dropping exisitng and adding new '_merge'\n",
    "\n",
    "#### -  df_customers \n",
    "(206209, 10)\n",
    "\n",
    "\n",
    "#### - df_final_merged\n",
    "(32404859, 34)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56e6f7f",
   "metadata": {},
   "source": [
    "## 8. Exporting the New Dataframe as a Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d81c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the \"df_final_merged\" dataframe as \"ords_prods_cust_merge\" for use in Part 2\n",
    "\n",
    "df_final_merged.to_pickle(os.path.join(path, '02 Data','Prepared Data', 'ords_prods_cust_merge.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e4a7c1-18d2-419f-90b8-632aa0dff97a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
