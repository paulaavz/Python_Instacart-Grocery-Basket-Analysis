{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a424005f",
   "metadata": {},
   "source": [
    "# 4.5. IC_ Data Consistency Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3e9f0",
   "metadata": {},
   "source": [
    "# 01.Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ccdfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries: pandas, NumPy and os.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e284ec",
   "metadata": {},
   "source": [
    "# 02. Importing Data Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb82606",
   "metadata": {},
   "source": [
    "Python Shortcut for Importing Data Files, using os.path.join() function\n",
    "\n",
    "path = r'/folderpath_to main project folder/'\n",
    "\n",
    "df = pd.read_csv(os.path.join(path,'folderpath','name.csv'), index_col = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "184de5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path to my main project folder is now stored within variable 'path'\n",
    "\n",
    "path = r'/Users/pau/06-05-2024 Instacart Basket Analysis'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37a64fa",
   "metadata": {},
   "source": [
    "#### Importing the “orders_wrangled.csv” data set into my Jupyter notebook using the os library as df_ords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac277fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the os.path.join() function to simplify the importing data and create dataframe: orders\n",
    "\n",
    "df_ords = pd.read_csv(os.path.join(path,'02 Data','Prepared Data','orders_wrangled.csv'), index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b8df8b",
   "metadata": {},
   "source": [
    "#### Importing the “products.csv” data set into my Jupyter notebook using the os library as df_prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72028247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the os.path.join() function to simplify the importing data and create dataframe: products\n",
    "\n",
    "df_prods = pd.read_csv(os.path.join(path,'02 Data', 'Original Data', 'products.csv'), index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0286894a",
   "metadata": {},
   "source": [
    "#### Checking the df are correctly loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "099adafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  order_id  user_id  order_number  orders_day_of_week  \\\n",
      "0           0   2539329        1             1                   2   \n",
      "1           1   2398795        1             2                   3   \n",
      "2           2    473747        1             3                   3   \n",
      "3           3   2254736        1             4                   4   \n",
      "4           4    431534        1             5                   4   \n",
      "\n",
      "   order_hour_of_day  days_since_prior_order  \n",
      "0                  8                     NaN  \n",
      "1                  7                    15.0  \n",
      "2                 12                    21.0  \n",
      "3                  7                    29.0  \n",
      "4                 15                    28.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3421083 entries, 0 to 3421082\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   Unnamed: 0              int64  \n",
      " 1   order_id                int64  \n",
      " 2   user_id                 int64  \n",
      " 3   order_number            int64  \n",
      " 4   orders_day_of_week      int64  \n",
      " 5   order_hour_of_day       int64  \n",
      " 6   days_since_prior_order  float64\n",
      "dtypes: float64(1), int64(6)\n",
      "memory usage: 182.7 MB\n",
      "None\n",
      "(3421083, 7)\n"
     ]
    }
   ],
   "source": [
    "# Checking \"orders_wrangled.csv\" data is correctly loaded\n",
    "print(df_ords.head())\n",
    "print(df_ords.info())\n",
    "print(df_ords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fcc4d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id                                       product_name  aisle_id  \\\n",
      "0           1                         Chocolate Sandwich Cookies        61   \n",
      "1           2                                   All-Seasons Salt       104   \n",
      "2           3               Robust Golden Unsweetened Oolong Tea        94   \n",
      "3           4  Smart Ones Classic Favorites Mini Rigatoni Wit...        38   \n",
      "4           5                          Green Chile Anytime Sauce         5   \n",
      "\n",
      "   department_id  prices  \n",
      "0             19     5.8  \n",
      "1             13     9.3  \n",
      "2              7     4.5  \n",
      "3              1    10.5  \n",
      "4             13     4.3  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 49693 entries, 0 to 49692\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   product_id     49693 non-null  int64  \n",
      " 1   product_name   49677 non-null  object \n",
      " 2   aisle_id       49693 non-null  int64  \n",
      " 3   department_id  49693 non-null  int64  \n",
      " 4   prices         49693 non-null  float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 1.9+ MB\n",
      "None\n",
      "(49693, 5)\n"
     ]
    }
   ],
   "source": [
    "# Checking \"products.csv\" data is correctly loaded\n",
    "print(df_prods.head())\n",
    "print(df_prods.info())\n",
    "print(df_prods.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed6775e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e40b0a9",
   "metadata": {},
   "source": [
    "# 03. Data Consistency Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c41689",
   "metadata": {},
   "source": [
    "### df.describe() function\n",
    "\n",
    "**The `df.describe()` function returns descriptive statistics for the numeric values in your dataframe.**\n",
    "\n",
    "- Using these results, you can begin investigating the accuracy of the columns in your dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f207962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>orders_day_of_week</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.214874e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.710541e+06</td>\n",
       "      <td>1.710542e+06</td>\n",
       "      <td>1.029782e+05</td>\n",
       "      <td>1.715486e+01</td>\n",
       "      <td>2.776219e+00</td>\n",
       "      <td>1.345202e+01</td>\n",
       "      <td>1.111484e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.875817e+05</td>\n",
       "      <td>9.875817e+05</td>\n",
       "      <td>5.953372e+04</td>\n",
       "      <td>1.773316e+01</td>\n",
       "      <td>2.046829e+00</td>\n",
       "      <td>4.226088e+00</td>\n",
       "      <td>9.206737e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.552705e+05</td>\n",
       "      <td>8.552715e+05</td>\n",
       "      <td>5.139400e+04</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.710541e+06</td>\n",
       "      <td>1.710542e+06</td>\n",
       "      <td>1.026890e+05</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.565812e+06</td>\n",
       "      <td>2.565812e+06</td>\n",
       "      <td>1.543850e+05</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.421082e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>2.062090e+05</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0      order_id       user_id  order_number  \\\n",
       "count  3.421083e+06  3.421083e+06  3.421083e+06  3.421083e+06   \n",
       "mean   1.710541e+06  1.710542e+06  1.029782e+05  1.715486e+01   \n",
       "std    9.875817e+05  9.875817e+05  5.953372e+04  1.773316e+01   \n",
       "min    0.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "25%    8.552705e+05  8.552715e+05  5.139400e+04  5.000000e+00   \n",
       "50%    1.710541e+06  1.710542e+06  1.026890e+05  1.100000e+01   \n",
       "75%    2.565812e+06  2.565812e+06  1.543850e+05  2.300000e+01   \n",
       "max    3.421082e+06  3.421083e+06  2.062090e+05  1.000000e+02   \n",
       "\n",
       "       orders_day_of_week  order_hour_of_day  days_since_prior_order  \n",
       "count        3.421083e+06       3.421083e+06            3.214874e+06  \n",
       "mean         2.776219e+00       1.345202e+01            1.111484e+01  \n",
       "std          2.046829e+00       4.226088e+00            9.206737e+00  \n",
       "min          0.000000e+00       0.000000e+00            0.000000e+00  \n",
       "25%          1.000000e+00       1.000000e+01            4.000000e+00  \n",
       "50%          3.000000e+00       1.300000e+01            7.000000e+00  \n",
       "75%          5.000000e+00       1.600000e+01            1.500000e+01  \n",
       "max          6.000000e+00       2.300000e+01            3.000000e+01  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the unnecessary \"eval_set\" column from the “orders.csv” file.\n",
    "\n",
    "df_ords.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48981e85",
   "metadata": {},
   "source": [
    "### Some of the most common checks to perform on data to confirm its consistency. \n",
    "These include:\n",
    "\n",
    "- **Finding and addressing mixed data types**\n",
    "- **Finding and addressing missing values**\n",
    "- **Finding and addressing duplicate records**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e14632",
   "metadata": {},
   "source": [
    "# 04. Mixed-Type Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53e5ec5",
   "metadata": {},
   "source": [
    "- a common reason for changing the data type of a column.\n",
    "- a mixed-type column is a column that includes both string values and numeric values.\n",
    "- Ex. if you had a column of names (string format), where missing values were marked with a “0” (numeric format).\n",
    "- When you import a data set into pandas, it will try to guess the data type of every column based on their most prevalent data types. However, when working with large data sets, it could get confused and decide not to assign a data type to a mixed-type column.\n",
    "- Always check for these mixed-type columns before moving forward with any analytical work, as they can break functions and generally cause problems in your procedures.\n",
    "- data prep and data analysis should be two discrete/separate stages in any data project.\n",
    "    - This holds true for your scripts, as well. *Analysis* scripts should never be interspersed/place in between with data *prep* scripts.\n",
    "\n",
    "- **Your Instacart data has already undergone all these data-prep checks, and you know there aren’t any mixed-type columns.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea2bb69",
   "metadata": {},
   "source": [
    " ### to practice fixing mixed-type columns now in your studies, so let’s create a small test dataframe for you to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "829bef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a new dataframe called df_test\n",
    "\n",
    "df_test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e975d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a mixed type column: \n",
    "# creates a new column, mix, within df_test and fills it with numeric, string, and boolean values\n",
    "\n",
    "df_test['mix'] = ['a', 'b', 1, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3355d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mix</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mix\n",
       "0     a\n",
       "1     b\n",
       "2     1\n",
       "3  True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the new mixed-typed column\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a466bf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mix\n"
     ]
    }
   ],
   "source": [
    "# function for checking whether a dataframe contains any mixed-type columns\n",
    "\n",
    "for col in df_test.columns.tolist():\n",
    "    weird = (df_test[[col]].map(type) != df_test[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "    if len (df_test[weird]) > 0:\n",
    "        print(col)\n",
    "        \n",
    "# structure used in this code is 'for-loop'\n",
    "# !=  Not equal\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fddccb7",
   "metadata": {},
   "source": [
    "- The structure that’s being used in this code is called a “for-loop.”\n",
    "    - The “for” in for-loop stands for “for these elements, do this,”\n",
    "    - and the “loop” describes how the structure works: looping over and over again as it performs the procedures detailed by the “for.”\n",
    "    - Here, the for-loop is *looping* through each column in the dataframe and executing the same block of code each time.\n",
    "    - Within the for-loop,\n",
    "        - a new variable is created: `weird`. Assigned to it is a test that checks whether the data types within the column are consistent.\n",
    "            - The `weird` variable will ultimately take a boolean value of either `True` or `False`.\n",
    "                - If `True`, that means the column contains inconsistent data types.\n",
    "                - If `False,` that means the column contains only one data type.\n",
    "                - Boolean values can also be represented by numbers: 0 as `False` and 1 as `True`.\n",
    "    - Here comes the “if” statement.\n",
    "        - An if statement checks if some condition is met, and if it’s met, executes a line of code. If the condition isn’t met, the code isn’t executed.\n",
    "            - Here, the if statement is checking whether `weird` is true or false.\n",
    "                - If it’s greater than 0, than it’s true. If not, it’s false.\n",
    "                - If `weird` is true, the command `print(col)` is executed, which prints the problematic column for you to see.\n",
    "                - Because of the for-loop, this command will be executed on every column in your dataframe, printing every mixed-type column it finds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010fee92",
   "metadata": {},
   "source": [
    "### How to fix mixed-type columns\n",
    "1st deciding what single data type the column in question should be. Based on the most freq. data type in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cce04be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change \"mix\" column data type to string\n",
    "\n",
    "df_test['mix'] = df_test['mix'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c437c1c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the results of the change\n",
    "df_test['mix'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d99dbee",
   "metadata": {},
   "source": [
    "# 04. Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c62c78",
   "metadata": {},
   "source": [
    "- missing values can occur for two reasons:\n",
    "    - 1) data corruption, or\n",
    "    - 2) they were never recorded in the first place.\n",
    "- IMP: investigate and address any missing values in your data when conducting an analysis in Python.\n",
    "- They can break your functions and throw errors in your analytical procedures.\n",
    "- IMP when deriving, or creating new variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8515746b",
   "metadata": {},
   "source": [
    "## How you can find and fix missing values in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c857a3",
   "metadata": {},
   "source": [
    "### Finding Missing Values\n",
    "\n",
    "#### df.isnull().sum()\n",
    "\n",
    "- the function `isnull()` to the `df_prods`dataframe, then sum the result with the attached `sum()` function.\n",
    "- The `isnull()` function\n",
    "    - is used to find missing observations/entries in your dataframe, like cells in Excel.\n",
    "    - If you were to use the `isnull()` function by itself,\n",
    "        - it would return a value of `True` or `False`, which, by itself, isn’t very helpful.\n",
    "    - You need to know how many total missing observations there are, which is where the `sum()` function comes in.\n",
    "        - `True`values can also be interpreted numerically as 1,\n",
    "        - and `False` values can also be interpreted numerically as 0.\n",
    "        - If every missing observation is equal to 1, then you can simply add them up using the `sum()` function to obtain the total number of missing observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dab41044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id        0\n",
       "product_name     16\n",
       "aisle_id          0\n",
       "department_id     0\n",
       "prices            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking for missing values in df_prods dataframe\n",
    "\n",
    "df_prods.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae7ed1a",
   "metadata": {},
   "source": [
    "the only column with missing values is the \"product_name\" column, and it’s missing 16 values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6309d73b",
   "metadata": {},
   "source": [
    "- To view these 16 values, you can create a subset of the df containing only the values in question.\n",
    "- Create a new dataframe, `df_nan`, containing only those values within the \"product_name\" column that meet the condition `isnull() = True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e6c0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of df_prods called \"df_nan\" that contains only the missing values from the \"product_name\" column\n",
    "\n",
    "df_nan = df_prods[df_prods['product_name'].isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0204addd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "      <th>prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>121</td>\n",
       "      <td>14</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>7</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>116</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93</td>\n",
       "      <td>3</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110</td>\n",
       "      <td>13</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>525</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109</td>\n",
       "      <td>11</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>1511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>16</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>1780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126</td>\n",
       "      <td>11</td>\n",
       "      <td>12.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2240</th>\n",
       "      <td>2240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>2586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>104</td>\n",
       "      <td>13</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>3159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>126</td>\n",
       "      <td>11</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>3230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>16</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3736</th>\n",
       "      <td>3736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41</td>\n",
       "      <td>8</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4283</th>\n",
       "      <td>4283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77</td>\n",
       "      <td>7</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4790</th>\n",
       "      <td>4790</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91</td>\n",
       "      <td>16</td>\n",
       "      <td>14.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38187</th>\n",
       "      <td>38183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>12</td>\n",
       "      <td>20.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40444</th>\n",
       "      <td>40440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120</td>\n",
       "      <td>16</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id product_name  aisle_id  department_id  prices\n",
       "33             34          NaN       121             14    12.2\n",
       "68             69          NaN        26              7    11.8\n",
       "115           116          NaN        93              3    10.8\n",
       "261           262          NaN       110             13    12.1\n",
       "525           525          NaN       109             11     1.2\n",
       "1511         1511          NaN        84             16    14.3\n",
       "1780         1780          NaN       126             11    12.3\n",
       "2240         2240          NaN        52              1    14.2\n",
       "2586         2586          NaN       104             13    12.4\n",
       "3159         3159          NaN       126             11    13.1\n",
       "3230         3230          NaN       120             16    14.4\n",
       "3736         3736          NaN        41              8    14.8\n",
       "4283         4283          NaN        77              7    14.4\n",
       "4790         4790          NaN        91             16    14.5\n",
       "38187       38183          NaN        39             12    20.9\n",
       "40444       40440          NaN       120             16    14.8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecec638",
   "metadata": {},
   "source": [
    "### Addressing Missing Values\n",
    "\n",
    "ways to deal with missing data:\n",
    "\n",
    "**1. Create a new variable that acts like a flag based on the missing value.**\n",
    "- When missing values actually hold just as much importance as the non-missing values. \n",
    "- Sol: create a new column containing the string values A or B.\n",
    "\n",
    "**2. Impute the value with the mean or median of the column (if variable is numeric).**\n",
    "- MEAN is a statistical measure that can be greatly influenced by extreme values.\n",
    "    - Use the **df.describe()function** to find the mean of the column in question.\n",
    "    - Code to replace missing values with mean: \n",
    "         - **df['column with missings'].fillna(mean value, inplace=True)**\n",
    "- MEDIAN \n",
    "    - Find it using the **df.median() function**.\n",
    "    - Code to replace missing values with median, same com. but with \"median\":\n",
    "      - **df['column with missings'].fillna(median value, inplace=True)**\n",
    "- alternative way to impute missing values is to use **Linear interpolation**, “connecting two points with a line”, dealing with missing data in time-series data, involves finding the mean of the rows before and after the missing value occurs, and estimating where the missing value should fall between those two means.\n",
    "- String values can’t be imputed like numeric values.\n",
    "    \n",
    "**3. Remove or filter out the missing data.**\n",
    "- when (string missing value) you can \n",
    "    - 1.  either **remove the missing values entirely**\n",
    "    - 2. or **filter out the ones that aren’t missing into a subset dataframe** and continue your analysis with this new dataframe.\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b34aff",
   "metadata": {},
   "source": [
    "#### df_nan: \n",
    "- The missing values are strings, so imputation is not possible. We will instead **create a new dataframe that excludes the missing values**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd294ff",
   "metadata": {},
   "source": [
    "#### creating a new dataframe that excludes the missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b474a007",
   "metadata": {},
   "source": [
    "\n",
    "- First check the **\"df_prods.shape\"** in order to later compare the number of rows in the original dataframe with the number in the new subset once the missing rows have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d964437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49693, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the rows in \"df_prods\"\n",
    "df_prods.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db541ad1",
   "metadata": {},
   "source": [
    "- create a new dataframe called `df_prods_clean`.\n",
    "    - use the same line of code from above, when you created the `df_nan`dataframe:  \n",
    "      - **df_nan = df_prods[df_prods['product_name'].isnull() == True]**\n",
    "    - this time setting the `isnull()` condition to `False`instead of `True`, you want *non-missing* values in your new dataframe as opposed to *missing* values: \n",
    "      - **df_prods_clean = df_prods[df_prods['product_name'].isnull() == False]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "566996dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe called df_prods_clean\n",
    "\n",
    "df_prods_clean = df_prods[df_prods['product_name'].isnull() == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82b9538",
   "metadata": {},
   "source": [
    "- run **df_prods_clean.shape** again to check that the number of rows has decreased.\n",
    "- new dataframe should have exactly 16 less rows than the original dataframe (the same as the number of missing values).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "012a3b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49677, 5)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the rows in the new subset (it should be 16 rows less than the original df_prods)\n",
    "\n",
    "df_prods_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f874a2c4",
   "metadata": {},
   "source": [
    "#### **Another way you can drop all missing values** is via the following command:\n",
    "\n",
    "```python\n",
    "df_prods.dropna(inplace = True)\n",
    "```\n",
    "\n",
    "#### If you wanted to use this command to drop only the NaNs from a particular column, the code would look like this:\n",
    "\n",
    "```python\n",
    "df_prods.dropna(subset = [‘product_name’], inplace = True)\n",
    "```\n",
    "\n",
    "- In both cases, **!!!rather than creating an entirely new dataframe, you’re overwriting `df_prods` with a new version of `df_prods` that doesn’t contain the missing values.!!!**\n",
    "    - This is done by way of the `inplace = True` function, which overwrites the original dataframe.\n",
    "    - If you don’t specify an `inplace` argument in your code, the function will take the default setting, which is `inplace = False`.\n",
    "        - When specified as `False`, the command will only return a *view* of the changed dataframe, leaving the original dataframe untouched.\n",
    "- As mentioned before, overwriting can be risky. Unless you’re absolutely sure it’s safe to drop the values in question, you should create a new dataframe instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf3276e",
   "metadata": {},
   "source": [
    "# 05. Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e9f5ba",
   "metadata": {},
   "source": [
    "- common occurrence when working with data. \n",
    "- they need to be handled with care and investigated thoroughly.\n",
    "-  important to know what kind of duplicates exist in your data. \n",
    "    - Oftentimes, you’ll need clarification from your client before proceeding with any data manipulation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd68e1",
   "metadata": {},
   "source": [
    "### Finding Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6a73ec",
   "metadata": {},
   "source": [
    "- you’ll want to look for full duplicates—multiple rows that have the exact same values in every column. \n",
    "- This is because single duplicates aren’t actually inconsistencies in your data. \n",
    "\n",
    "command will look for full duplicates within your dataframe:\n",
    "\n",
    "```python\n",
    "df_dups = df_prods_clean[df_prods_clean.duplicated()]\n",
    "```\n",
    "\n",
    "-  This code creates a new subset of `df_prods_clean`—`df_dups`—containing *only* rows that are duplicates.\n",
    "    - The `duplicated()`function is what identifies duplicate rows.\n",
    "    - It’s run on the `df_prods_clean` dataframe.\n",
    "    - Any duplicate rows that it finds are saved within the new `df_dups` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e69b1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates in df_prods_clean by creating a new subset that contains only duplicates\n",
    "\n",
    "df_dups = df_prods_clean[df_prods_clean.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "090461e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "      <th>prices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>462</td>\n",
       "      <td>Fiber 4g Gummy Dietary Supplement</td>\n",
       "      <td>70</td>\n",
       "      <td>11</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18459</th>\n",
       "      <td>18458</td>\n",
       "      <td>Ranger IPA</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26810</th>\n",
       "      <td>26808</td>\n",
       "      <td>Black House Coffee Roasty Stout Beer</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35309</th>\n",
       "      <td>35306</td>\n",
       "      <td>Gluten Free Organic Peanut Butter &amp; Chocolate ...</td>\n",
       "      <td>121</td>\n",
       "      <td>14</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35495</th>\n",
       "      <td>35491</td>\n",
       "      <td>Adore Forever Body Wash</td>\n",
       "      <td>127</td>\n",
       "      <td>11</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id                                       product_name  \\\n",
       "462           462                  Fiber 4g Gummy Dietary Supplement   \n",
       "18459       18458                                         Ranger IPA   \n",
       "26810       26808               Black House Coffee Roasty Stout Beer   \n",
       "35309       35306  Gluten Free Organic Peanut Butter & Chocolate ...   \n",
       "35495       35491                            Adore Forever Body Wash   \n",
       "\n",
       "       aisle_id  department_id  prices  \n",
       "462          70             11     4.8  \n",
       "18459        27              5     9.2  \n",
       "26810        27              5    13.4  \n",
       "35309       121             14     6.8  \n",
       "35495       127             11     9.9  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling the df_dups dataframe. \n",
    "# This will display all the duplicate rows within the dataframe df_prods_clean\n",
    "\n",
    "df_dups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2812b8",
   "metadata": {},
   "source": [
    "### Addressing Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8107d549",
   "metadata": {},
   "source": [
    "1. check the current number of rows in your df_prods_clean dataframe so that you can compare the number after removing the duplicates\n",
    "\n",
    "2. Next, create a new dataframe that doesn’t include the duplicates you just identified using the drop_duplicates() function:\n",
    "\n",
    "#### df.drop_duplicates()\n",
    "\n",
    "- function to delete duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bcee9b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49677, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of rows in \"df_prods_clean\" before removing the duplicates\n",
    "\n",
    "df_prods_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88e42c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe that doesn't include the duplicates\n",
    "\n",
    "df_prods_clean_no_dups = df_prods_clean.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cadd4ee",
   "metadata": {},
   "source": [
    "This command has created a new dataframe: **df_prods_clean_no_dups** that contains only the unique rows from df_prods_clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a86b4c2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49672, 5)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of rows in the new dataframe (it should be 5 less than the original df_prods_clean)\n",
    "df_prods_clean_no_dups.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e520eaed",
   "metadata": {},
   "source": [
    "now we have 49,672 rows in our dataframe. The five duplicates have been successfully deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45f751e",
   "metadata": {},
   "source": [
    "# 06. Tidying Up and Exporting Changes:\n",
    "\n",
    "## Exporting the new cleaned Products dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5433a36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id                                       product_name  aisle_id  \\\n",
      "0           1                         Chocolate Sandwich Cookies        61   \n",
      "1           2                                   All-Seasons Salt       104   \n",
      "2           3               Robust Golden Unsweetened Oolong Tea        94   \n",
      "3           4  Smart Ones Classic Favorites Mini Rigatoni Wit...        38   \n",
      "4           5                          Green Chile Anytime Sauce         5   \n",
      "\n",
      "   department_id  prices  \n",
      "0             19     5.8  \n",
      "1             13     9.3  \n",
      "2              7     4.5  \n",
      "3              1    10.5  \n",
      "4             13     4.3  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 49672 entries, 0 to 49692\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   product_id     49672 non-null  int64  \n",
      " 1   product_name   49672 non-null  object \n",
      " 2   aisle_id       49672 non-null  int64  \n",
      " 3   department_id  49672 non-null  int64  \n",
      " 4   prices         49672 non-null  float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 2.3+ MB\n",
      "None\n",
      "(49672, 5)\n"
     ]
    }
   ],
   "source": [
    "# Perform a final check of the dataframe before exporting\n",
    "print(df_prods_clean_no_dups.head())\n",
    "print(df_prods_clean_no_dups.info())\n",
    "print(df_prods_clean_no_dups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5604c7fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_prods_clean_no_dups' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_prods_clean_no_dups\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_prods_clean_no_dups' is not defined"
     ]
    }
   ],
   "source": [
    "df_prods_clean_no_dups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a88e57db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prods_clean_no_dups.to_csv(os.path.join(path, '02 Data', 'Prepared Data', 'products_checked.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a4b5b0",
   "metadata": {},
   "source": [
    "# ______________________________________________\n",
    "\n",
    "\n",
    " # Task 4.5. \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a799be2",
   "metadata": {},
   "source": [
    "## 01.  Data Consistency Checks on the \"df_prods\" dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb07921",
   "metadata": {},
   "source": [
    "Data consistency checks performed during this exercise and exported the new cleaned Products dataframe as 'products_checked.csv' and stored it in your “Prepared Data” folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee5b585",
   "metadata": {},
   "source": [
    "## Data Consistency Checks on the \"df_ords\" dataframe\n",
    "\n",
    "\n",
    "## 02. Run the df.describe() function on the \"df_ords\" dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b003ecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>orders_day_of_week</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>3.214874e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.710541e+06</td>\n",
       "      <td>1.710542e+06</td>\n",
       "      <td>1.029782e+05</td>\n",
       "      <td>1.715486e+01</td>\n",
       "      <td>2.776219e+00</td>\n",
       "      <td>1.345202e+01</td>\n",
       "      <td>1.111484e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.875817e+05</td>\n",
       "      <td>9.875817e+05</td>\n",
       "      <td>5.953372e+04</td>\n",
       "      <td>1.773316e+01</td>\n",
       "      <td>2.046829e+00</td>\n",
       "      <td>4.226088e+00</td>\n",
       "      <td>9.206737e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.552705e+05</td>\n",
       "      <td>8.552715e+05</td>\n",
       "      <td>5.139400e+04</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+01</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.710541e+06</td>\n",
       "      <td>1.710542e+06</td>\n",
       "      <td>1.026890e+05</td>\n",
       "      <td>1.100000e+01</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>1.300000e+01</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.565812e+06</td>\n",
       "      <td>2.565812e+06</td>\n",
       "      <td>1.543850e+05</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>1.600000e+01</td>\n",
       "      <td>1.500000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.421082e+06</td>\n",
       "      <td>3.421083e+06</td>\n",
       "      <td>2.062090e+05</td>\n",
       "      <td>1.000000e+02</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>2.300000e+01</td>\n",
       "      <td>3.000000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0      order_id       user_id  order_number  \\\n",
       "count  3.421083e+06  3.421083e+06  3.421083e+06  3.421083e+06   \n",
       "mean   1.710541e+06  1.710542e+06  1.029782e+05  1.715486e+01   \n",
       "std    9.875817e+05  9.875817e+05  5.953372e+04  1.773316e+01   \n",
       "min    0.000000e+00  1.000000e+00  1.000000e+00  1.000000e+00   \n",
       "25%    8.552705e+05  8.552715e+05  5.139400e+04  5.000000e+00   \n",
       "50%    1.710541e+06  1.710542e+06  1.026890e+05  1.100000e+01   \n",
       "75%    2.565812e+06  2.565812e+06  1.543850e+05  2.300000e+01   \n",
       "max    3.421082e+06  3.421083e+06  2.062090e+05  1.000000e+02   \n",
       "\n",
       "       orders_day_of_week  order_hour_of_day  days_since_prior_order  \n",
       "count        3.421083e+06       3.421083e+06            3.214874e+06  \n",
       "mean         2.776219e+00       1.345202e+01            1.111484e+01  \n",
       "std          2.046829e+00       4.226088e+00            9.206737e+00  \n",
       "min          0.000000e+00       0.000000e+00            0.000000e+00  \n",
       "25%          1.000000e+00       1.000000e+01            4.000000e+00  \n",
       "50%          3.000000e+00       1.300000e+01            7.000000e+00  \n",
       "75%          5.000000e+00       1.600000e+01            1.500000e+01  \n",
       "max          6.000000e+00       2.300000e+01            3.000000e+01  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start by running the \"df.describe()\" function\n",
    "\n",
    "df_ords.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d745ca22",
   "metadata": {},
   "source": [
    "**Output**\n",
    "\n",
    "The df.describe() function returns descriptive statistics for the numeric values in the dataframe.\n",
    "Using these results, we can begin investigating the accuracy of the columns in the df_ords  dataframe\n",
    "\n",
    "#### Order Number: \n",
    "- The maximum order number is 100, suggesting that only up to 100 orders per customer are kept in the data.\n",
    "#### Order Day of the Week: \n",
    "- Ranges from 0 to 6, correctly representing a full week.\n",
    "#### Order Hour of Day: \n",
    "- Ranges from 0 to 23, representing each hour of the day.\n",
    "#### Days Since Prior Order: \n",
    "- The count is less than other columns, which could mean missing values: 3.421083e+06 > 3.214874e+06"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4811b0af",
   "metadata": {},
   "source": [
    "## 03. Check for mixed-type data in your df_ords dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f977d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check \"df_ords\" for any mixed-type columns with the exercise function\n",
    "\n",
    "for col in df_ords.columns.tolist():\n",
    "    weird = (df_ords[[col]].map(type) != df_ords[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "    if len (df_ords[weird]) > 0:\n",
    "        print (col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0f1a97f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mixed-type data in column: Unnamed: 0\n",
      "No mixed-type data in column: order_id\n",
      "No mixed-type data in column: user_id\n",
      "No mixed-type data in column: order_number\n",
      "No mixed-type data in column: orders_day_of_week\n",
      "No mixed-type data in column: order_hour_of_day\n",
      "No mixed-type data in column: days_since_prior_order\n"
     ]
    }
   ],
   "source": [
    "# Double checking with alternative method for identifying columns with mixed-type data\n",
    "\n",
    "for col in df_ords.columns.tolist():\n",
    "    weird = (df_ords[[col]].map(type) != df_ords[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "    if len (df_ords[weird]) > 0:\n",
    "        print (f\"Mixed-type data found in column: {col}\")\n",
    "    else: print(f\"No mixed-type data in column: {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29232505",
   "metadata": {},
   "source": [
    "#### Output: \"df_ords\" appears to have no columns with mixed-type data to correct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eaffe29",
   "metadata": {},
   "source": [
    "## 05. Run a check for missing values in your df_ords dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4246403",
   "metadata": {},
   "source": [
    "#### 1. To find missing values we are going to use the function:\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d6bd4df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                     0\n",
       "order_id                       0\n",
       "user_id                        0\n",
       "order_number                   0\n",
       "orders_day_of_week             0\n",
       "order_hour_of_day              0\n",
       "days_since_prior_order    206209\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look for missing values in df_ords dataframe\n",
    "\n",
    "df_ords.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e65b877",
   "metadata": {},
   "source": [
    "#### 2. Interpreting the results:\n",
    "\n",
    "#### The \"days_since_prior_order\" column has missing values as was suspected after running the \"df_ords.describe()\" function above.\n",
    "\n",
    "- Since \"days_since_prior_order\" has a MAX value of 30, the missing values could represent customers who haven't placed an order in the last 30 days. \n",
    "- Another explanation is the missing value represents customers who haven't placed an order yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9da7958",
   "metadata": {},
   "source": [
    "#### 3. Examining the missing values:\n",
    "\n",
    "- To view these 206209 values, we can create a subset of the df containing only the values in question.\n",
    "- Create a new dataframe, `df_ords_nan`, containing only those values within the \"days_since_prior_order\" column that meet the condition `isnull() = True`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d9d36a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To more closely examine the rows with missing values, create a subset containing only those rows\n",
    "\n",
    "df_ords_nan = df_ords[df_ords['days_since_prior_order'].isnull() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9088d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>orders_day_of_week</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>2168274</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1374495</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>3343014</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>45</td>\n",
       "      <td>2717275</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420930</th>\n",
       "      <td>3420930</td>\n",
       "      <td>969311</td>\n",
       "      <td>206205</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420934</th>\n",
       "      <td>3420934</td>\n",
       "      <td>3189322</td>\n",
       "      <td>206206</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421002</th>\n",
       "      <td>3421002</td>\n",
       "      <td>2166133</td>\n",
       "      <td>206207</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421019</th>\n",
       "      <td>3421019</td>\n",
       "      <td>2227043</td>\n",
       "      <td>206208</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421069</th>\n",
       "      <td>3421069</td>\n",
       "      <td>3154581</td>\n",
       "      <td>206209</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206209 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  order_id  user_id  order_number  orders_day_of_week  \\\n",
       "0                 0   2539329        1             1                   2   \n",
       "11               11   2168274        2             1                   2   \n",
       "26               26   1374495        3             1                   1   \n",
       "39               39   3343014        4             1                   6   \n",
       "45               45   2717275        5             1                   3   \n",
       "...             ...       ...      ...           ...                 ...   \n",
       "3420930     3420930    969311   206205             1                   4   \n",
       "3420934     3420934   3189322   206206             1                   3   \n",
       "3421002     3421002   2166133   206207             1                   6   \n",
       "3421019     3421019   2227043   206208             1                   1   \n",
       "3421069     3421069   3154581   206209             1                   3   \n",
       "\n",
       "         order_hour_of_day  days_since_prior_order  \n",
       "0                        8                     NaN  \n",
       "11                      11                     NaN  \n",
       "26                      14                     NaN  \n",
       "39                      11                     NaN  \n",
       "45                      12                     NaN  \n",
       "...                    ...                     ...  \n",
       "3420930                 12                     NaN  \n",
       "3420934                 18                     NaN  \n",
       "3421002                 19                     NaN  \n",
       "3421019                 15                     NaN  \n",
       "3421069                 11                     NaN  \n",
       "\n",
       "[206209 rows x 7 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ords_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98b7ffe",
   "metadata": {},
   "source": [
    "#### Output\n",
    "\n",
    "#### It appears that all the \"days_since_prior_order\" NaNs occur when the \"order_number\" is 1. \n",
    "It could mean that when a customer places a first order and since the system has no prior order to reference it fills this column with \"NaN\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8384f84b",
   "metadata": {},
   "source": [
    "## 06. Address the missing values using an appropriate method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba536a60",
   "metadata": {},
   "source": [
    "#### To address the missing values in \"days_since_prior_order\" (assuming all NaNs correspond to an \"order_number\" of 1), I will create a new column to flag the first time orders, then count the number of flags to see if it equals the number of \"NaN\"s in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "532c0c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column to flag first orders with either 1 (it is a first time order) or 0 (it is not a first time order)\n",
    "\n",
    "df_ords['is_first_order'] = df_ords['days_since_prior_order'].isnull().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce70a449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206209\n"
     ]
    }
   ],
   "source": [
    "# Counting the number of first time orders\n",
    "\n",
    "print(df_ords['is_first_order'].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9e34dc",
   "metadata": {},
   "source": [
    "#### This confirms that all first time orders are given \"NaN\" in the \"days_since_prior_order\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1317c089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>orders_day_of_week</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>is_first_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2398795</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>473747</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2254736</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>431534</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  order_id  user_id  order_number  orders_day_of_week  \\\n",
       "0           0   2539329        1             1                   2   \n",
       "1           1   2398795        1             2                   3   \n",
       "2           2    473747        1             3                   3   \n",
       "3           3   2254736        1             4                   4   \n",
       "4           4    431534        1             5                   4   \n",
       "\n",
       "   order_hour_of_day  days_since_prior_order  is_first_order  \n",
       "0                  8                     NaN               1  \n",
       "1                  7                    15.0               0  \n",
       "2                 12                    21.0               0  \n",
       "3                  7                    29.0               0  \n",
       "4                 15                    28.0               0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the top rows to confirm the new \"flag\" column\n",
    "\n",
    "df_ords.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef7e585",
   "metadata": {},
   "source": [
    "## 07. Run a check for duplicate values in your df_ords data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48d6aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicates in df_ords by creating a new subset that contains only duplicates\n",
    "\n",
    "df_ords_dups = df_ords[df_ords.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f507f7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>orders_day_of_week</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>is_first_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, order_id, user_id, order_number, orders_day_of_week, order_hour_of_day, days_since_prior_order, is_first_order]\n",
       "Index: []"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calling the df_ords_dups dataframe. \n",
    "# This will display all the duplicate rows within the dataframe df_ords\n",
    "\n",
    "df_ords_dups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e29d76f",
   "metadata": {},
   "source": [
    "#### Output: No duplicate values were found in the orders dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4abd04",
   "metadata": {},
   "source": [
    "## 09. Export your final, cleaned df_prods and df_ords data as “.csv” files in your “Prepared Data” folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d72ded",
   "metadata": {},
   "source": [
    "#### Export of the final, cleaned \"df_prods\" data was already performed above. New csv file created \"products_checked.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ab91793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  order_id  user_id  order_number  orders_day_of_week  \\\n",
      "0           0   2539329        1             1                   2   \n",
      "1           1   2398795        1             2                   3   \n",
      "2           2    473747        1             3                   3   \n",
      "3           3   2254736        1             4                   4   \n",
      "4           4    431534        1             5                   4   \n",
      "\n",
      "   order_hour_of_day  days_since_prior_order  is_first_order  \n",
      "0                  8                     NaN               1  \n",
      "1                  7                    15.0               0  \n",
      "2                 12                    21.0               0  \n",
      "3                  7                    29.0               0  \n",
      "4                 15                    28.0               0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3421083 entries, 0 to 3421082\n",
      "Data columns (total 8 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   Unnamed: 0              int64  \n",
      " 1   order_id                int64  \n",
      " 2   user_id                 int64  \n",
      " 3   order_number            int64  \n",
      " 4   orders_day_of_week      int64  \n",
      " 5   order_hour_of_day       int64  \n",
      " 6   days_since_prior_order  float64\n",
      " 7   is_first_order          int64  \n",
      "dtypes: float64(1), int64(7)\n",
      "memory usage: 208.8 MB\n",
      "None\n",
      "(3421083, 8)\n"
     ]
    }
   ],
   "source": [
    "# Perform a final check of the dataframe before exporting\n",
    "print(df_ords.head())\n",
    "print(df_ords.info())\n",
    "print(df_ords.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7287c5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the final cleaned \"df_ords\" data as \"orders_checked.csv\"\n",
    "\n",
    "df_ords.to_csv(os.path.join(path, '02 Data', 'Prepared Data', 'orders_checked.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51824c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e9c27-05e1-408b-ad1a-28323418177d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
