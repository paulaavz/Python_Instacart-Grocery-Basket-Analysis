{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a424005f",
   "metadata": {},
   "source": [
    "# 4.6.1. IC_Combining & Exporting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12952c4e",
   "metadata": {},
   "source": [
    "#### Context:\n",
    "- We want to combine our dataframes: **`df_ords` and `df_prods`**\n",
    "- `df_ords` and `df_prods` dataframes don’t contain a common column. \n",
    "- To solve this problem, we’ll combine our `df_ords` dataframe with a new dataframe called `orders_products_prior`.\n",
    "   - Merge these using 'order_id'. \n",
    "   - This new dataframe contains a “product_id” column—the same as our `df_prods` dataframe.\n",
    "   - By adding this column to our `df_ords` dataframe, we’ll have created a common column between `df_ords` and `df_prods`, paving the way for a successful merge.\n",
    "   \n",
    "#### Notebook Part 1:\n",
    "- merging our prepared Instacart orders data with the new orders_products_prior dataframe\n",
    "    - Merge \"df_ords_prior\" with \"df_ords\", using 'order_id'.\n",
    "    - Using the indicator argument to check whether there was a full match between the two dataframes.\n",
    "    - Checking the results of the merge using the \"value_counts()\" function - full match.\n",
    "- Exporting the merged file in pickle format as “orders_products_combined.pkl”.\n",
    "\n",
    "#### Notebook Part 2:\n",
    "- new notebook, importing the “orders_products_combined.pkl” dataframe from the pickle file.\n",
    "- importing our wrangled, cleaned, and debuped products data set stored in our “Prepared Data” folder from the previous step.\n",
    "- Checking the shape of the imported dataframes.\n",
    "- Determining a suitable way to combine the orders_products_combined dataframe with our products data set. \n",
    "    - Before merging, we will drop the unnecessary columns from both dataframes.\n",
    "- Confirming the results of the merge using the merge flag.\n",
    "- Exporting the newly created dataframe as ords_prods_merge in a suitable format (taking into consideration the size).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35aeb4ec",
   "metadata": {},
   "source": [
    "### This script contains the following points:\n",
    "\n",
    "#### 0. Importing Libraries\n",
    "#### 1. Loading and Checking the Data\n",
    "#### 2. Merging Dataframes\n",
    "#### 3. Exporting Merged Dataframe as Pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3e9f0",
   "metadata": {},
   "source": [
    "## 0. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91ccdfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries: pandas, NumPy and os.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e284ec",
   "metadata": {},
   "source": [
    "## 1. Loading and Checking the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb82606",
   "metadata": {},
   "source": [
    "Importing Data Files, using os.path.join() function\n",
    "\n",
    "path = r'/folderpath_to main project folder/'\n",
    "\n",
    "df = pd.read_csv(os.path.join(path,'folderpath','name.csv'), index_col = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "184de5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder path to my main project folder is now stored within variable 'path'\n",
    "\n",
    "path = r'/Users/pau/06-05-2024 Instacart Basket Analysis'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37a64fa",
   "metadata": {},
   "source": [
    "#### Importing the “orders_products_prior.csv” data set into my Jupyter notebook using the os library as df_ords_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac277fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the “orders_products_prior.csv” data set from the “Original Data” folder as df_ords_prior \n",
    "\n",
    "df_ords_prior = pd.read_csv(os.path.join(path,'02 Data','Original Data','orders_products_prior.csv'), index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b8df8b",
   "metadata": {},
   "source": [
    "#### Importing the “orders_checked.csv” (the most up to date version) data set into my Jupyter notebook using the os library as df_ords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72028247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the “orders_checked.csv” data set from your “Prepared Data” folder as df_ords\n",
    "\n",
    "df_ords = pd.read_csv(os.path.join(path,'02 Data', 'Prepared Data', 'orders_checked.csv'), index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0286894a",
   "metadata": {},
   "source": [
    "#### Checking the dimensions of the imported dataframe and if the data is correctly loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "099adafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  product_id  add_to_cart_order  reordered\n",
      "0         2       33120                  1          1\n",
      "1         2       28985                  2          1\n",
      "2         2        9327                  3          0\n",
      "3         2       45918                  4          1\n",
      "4         2       30035                  5          0\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32434489 entries, 0 to 32434488\n",
      "Data columns (total 4 columns):\n",
      " #   Column             Dtype\n",
      "---  ------             -----\n",
      " 0   order_id           int64\n",
      " 1   product_id         int64\n",
      " 2   add_to_cart_order  int64\n",
      " 3   reordered          int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 989.8 MB\n",
      "None\n",
      "(32434489, 4)\n"
     ]
    }
   ],
   "source": [
    "# Checking \"orders_products_prior.csv\" data is correctly loaded\n",
    "\n",
    "print(df_ords_prior.head()) # to ensure nothing looks off about our imported dataframes.\n",
    "print(df_ords_prior.info()) # \n",
    "print(df_ords_prior.shape) # to confirm the total size of our imported df. Great way to get a feel for the data and have a better idea how to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fcc4d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0  order_id  user_id  order_number  \\\n",
      "0             0           0   2539329        1             1   \n",
      "1             1           1   2398795        1             2   \n",
      "2             2           2    473747        1             3   \n",
      "3             3           3   2254736        1             4   \n",
      "4             4           4    431534        1             5   \n",
      "\n",
      "   orders_day_of_week  order_hour_of_day  days_since_prior_order  \\\n",
      "0                   2                  8                     NaN   \n",
      "1                   3                  7                    15.0   \n",
      "2                   3                 12                    21.0   \n",
      "3                   4                  7                    29.0   \n",
      "4                   4                 15                    28.0   \n",
      "\n",
      "   is_first_order  \n",
      "0               1  \n",
      "1               0  \n",
      "2               0  \n",
      "3               0  \n",
      "4               0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3421083 entries, 0 to 3421082\n",
      "Data columns (total 9 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   Unnamed: 0.1            int64  \n",
      " 1   Unnamed: 0              int64  \n",
      " 2   order_id                int64  \n",
      " 3   user_id                 int64  \n",
      " 4   order_number            int64  \n",
      " 5   orders_day_of_week      int64  \n",
      " 6   order_hour_of_day       int64  \n",
      " 7   days_since_prior_order  float64\n",
      " 8   is_first_order          int64  \n",
      "dtypes: float64(1), int64(8)\n",
      "memory usage: 234.9 MB\n",
      "None\n",
      "(3421083, 9)\n"
     ]
    }
   ],
   "source": [
    "# Checking \"orders_checked.csv\" data is correctly loaded\n",
    "\n",
    "print(df_ords.head())\n",
    "print(df_ords.info())\n",
    "print(df_ords.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48452671",
   "metadata": {},
   "source": [
    "- New dataframe, df_ords_prior, is quite large, because it contains each and every order of each and every user—as well as what exactly they ordered.\n",
    "- df_ords_prior and df_ords, different shape but shared column: “order_id.”\n",
    "    - In theory, we should have a fully matching “order_id” column, so we shouldn’t need to specify a type of join - default type for a join \"inner\", so the resulting ds will only contain observations included in both input data sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e40b0a9",
   "metadata": {},
   "source": [
    "## 2. Merging Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c398c586",
   "metadata": {},
   "source": [
    "- Merge \"df_ords_prior\" with \"df_ords\"\n",
    "- Use the indicator argument to check whether there was a full match between the two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d290a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge \"df_ords_prior\" with \"df_ords\"\n",
    "\n",
    "df_merged_large = df_ords.merge(df_ords_prior, on = 'order_id', indicator = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45dbde71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>orders_day_of_week</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>is_first_order</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>_merge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>14084</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>12427</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>26088</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>26405</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>both</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  order_id  user_id  order_number  \\\n",
       "0             0           0   2539329        1             1   \n",
       "1             0           0   2539329        1             1   \n",
       "2             0           0   2539329        1             1   \n",
       "3             0           0   2539329        1             1   \n",
       "4             0           0   2539329        1             1   \n",
       "\n",
       "   orders_day_of_week  order_hour_of_day  days_since_prior_order  \\\n",
       "0                   2                  8                     NaN   \n",
       "1                   2                  8                     NaN   \n",
       "2                   2                  8                     NaN   \n",
       "3                   2                  8                     NaN   \n",
       "4                   2                  8                     NaN   \n",
       "\n",
       "   is_first_order  product_id  add_to_cart_order  reordered _merge  \n",
       "0               1         196                  1          0   both  \n",
       "1               1       14084                  2          0   both  \n",
       "2               1       12427                  3          0   both  \n",
       "3               1       26088                  4          0   both  \n",
       "4               1       26405                  5          0   both  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming the results of the merge\n",
    "\n",
    "df_merged_large.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd4aab66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_merge\n",
       "both          32434489\n",
       "left_only            0\n",
       "right_only           0\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the results of the merge using the \"value_counts()\" function\n",
    "\n",
    "df_merged_large['_merge'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8dc327",
   "metadata": {},
   "source": [
    "- Using the value_counts() function lets us quickly sum up all the values in the “_merge” column, letting us see instantly whether we have a full match or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2606c246",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "- Let’s see what the merge flag frequency shows you here.\n",
    "    - In the “_merge” column, you can see that there are only entries that have a value of “both,” leading you to think that your key column, “order_id,” exists completely in both dataframes.\n",
    "    - However, this conclusion is *wrong*.\n",
    " \n",
    " \n",
    "- What pandas does here is fill in information about each product for every “order_id” in the `df_ords` dataframe, which is why the resulting dataframe has 32,434,489 rows (the same total count as the `df_ords_prior` dataframe).\n",
    "- But does this mean that you have a full match? The answer is no. There’s one particular intricacy when using and interpreting the merge flag, and it has a lot to do with the way you chose to merge the dataframes.\n",
    "\n",
    "    - In this case, you chose the default option of *inner join*. This means that the resulting table will only contain observations found in both dataframes. As such, the merge flag here will only show entries that have a value of “both.” How, then, can you check whether you really have a full match?\n",
    "    - Check out the output which shows the frequency of a merge using the argument `how = 'outer'`(not shown in the code above). Merging like this will combine all the observations and show you the real merge rate:\n",
    "        - The results of a merge using the argument how = 'outer'. \n",
    "        - The merge flags show us there is not a full match between the two input dataframes.\n",
    "        - After using this method to double-check your merge, you can see that you don’t actually have a full match. \n",
    "               \n",
    "\n",
    "#### You should always double-check your merge rates using an outer join, as well, especially when you’re exploring new data and performing test merges.\n",
    "- For your Instacart project, you’ll only be working with data sets that have a full merge rate, so you won’t need to worry about this or apply any changes to the merge you just completed (using `how = 'inner'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6df3a7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32434489, 13)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_large.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf268ea",
   "metadata": {},
   "source": [
    "we should always pay attention to the initial and final shape of the df:\n",
    "\n",
    "- df_ords_prior : (32434489, 4)\n",
    "- df_ords: ( 3421083, 9)\n",
    "\n",
    "#### df_merged_larged: (32434489, 13) rows exact same num. as df_ords_prior, cols from both df were added, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647e181a",
   "metadata": {},
   "source": [
    "## 3. Export the merged dataframe as a Pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e77795",
   "metadata": {},
   "source": [
    "- A **pickle**, or “.pkl,”\n",
    "    - is a pandas format used to store data on your computer.\n",
    "    - While it’s similar to “.csv” files, pickles can only be opened using Python.\n",
    "    - Importing a pickle into your Jupyter notebook follows the same procedure as importing a “.csv” file and produces the same dataframe.\n",
    "    \n",
    "- the biggest difference when it comes to importing and exporting “.csv” files and “.pkl” files is efficiency.\n",
    "    - Your `df_merged_large` dataframe, for instance, would likely take around two minutes to export as a pickle, while it could take upwards of ten minutes to export as a “.csv” file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9c17bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0.1  Unnamed: 0  order_id  user_id  order_number  \\\n",
      "0             0           0   2539329        1             1   \n",
      "1             0           0   2539329        1             1   \n",
      "2             0           0   2539329        1             1   \n",
      "3             0           0   2539329        1             1   \n",
      "4             0           0   2539329        1             1   \n",
      "\n",
      "   orders_day_of_week  order_hour_of_day  days_since_prior_order  \\\n",
      "0                   2                  8                     NaN   \n",
      "1                   2                  8                     NaN   \n",
      "2                   2                  8                     NaN   \n",
      "3                   2                  8                     NaN   \n",
      "4                   2                  8                     NaN   \n",
      "\n",
      "   is_first_order  product_id  add_to_cart_order  reordered _merge  \n",
      "0               1         196                  1          0   both  \n",
      "1               1       14084                  2          0   both  \n",
      "2               1       12427                  3          0   both  \n",
      "3               1       26088                  4          0   both  \n",
      "4               1       26405                  5          0   both  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32434489 entries, 0 to 32434488\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Dtype   \n",
      "---  ------                  -----   \n",
      " 0   Unnamed: 0.1            int64   \n",
      " 1   Unnamed: 0              int64   \n",
      " 2   order_id                int64   \n",
      " 3   user_id                 int64   \n",
      " 4   order_number            int64   \n",
      " 5   orders_day_of_week      int64   \n",
      " 6   order_hour_of_day       int64   \n",
      " 7   days_since_prior_order  float64 \n",
      " 8   is_first_order          int64   \n",
      " 9   product_id              int64   \n",
      " 10  add_to_cart_order       int64   \n",
      " 11  reordered               int64   \n",
      " 12  _merge                  category\n",
      "dtypes: category(1), float64(1), int64(11)\n",
      "memory usage: 2.9 GB\n",
      "None\n",
      "(32434489, 13)\n"
     ]
    }
   ],
   "source": [
    "# Perform a final check of the dataframe before exporting\n",
    "\n",
    "print(df_merged_large.head())\n",
    "print(df_merged_large.info())\n",
    "print(df_merged_large.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85a6002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export data to pkl as 'df_merged_large'\n",
    "\n",
    "df_merged_large.to_pickle(os.path.join(path, '02 Data', 'Prepared Data', 'orders_products_combined.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87848038",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51824c56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
